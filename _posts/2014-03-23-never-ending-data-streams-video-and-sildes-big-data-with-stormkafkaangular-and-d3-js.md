---
layout: post
title: Never-Ending Data Streams video and sildes - Big Data with Storm,Kafka,Angular
  and D3.js
created: 1395567127
author: yifat
permalink: /never-ending-data-streams-video-and-sildes-big-data-stormkafkaangular-and-d3js
tags:
- Incubator
- incubator
- Java
- bigdata
- Angular
- Storm
- Kafka
- d3.js
---
<table border="0" cellpadding="2" cellspacing="2" style="width: 100%;">
	<tbody>
		<tr>
			<td style="width: 105px;">
			<p>&nbsp;&nbsp;<img alt="" src="http://www.tikalk.com/files/fullstack-logo.png" style="line-height: 1.6em; width: 80px; height: 80px;" /></p>
			</td>
			<td colspan="2">
			<h2>Never-Ending Data Streams</h2>
			</td>
		</tr>
		<tr>
			<td colspan="3"><img alt="" src="http://www.tikalk.com/files/fs-event2.png" style="height: 237px; width: 600px;" /></td>
		</tr>
		<tr>
			<td colspan="3">
			<p>Following the succesfull Fullstack event with over 330 members, we are happy to share the slides and video&#39;s from the event.<br />
			This evnet was about how Storm supports the construction of topologies that transform unterminated streams of data.</p>

			<p><font color="#333333"><a href="http://www.meetup.com/full-stack-developer-il/events/166864612/">Read the event full agenda, comments, and reviews</a>.&nbsp;</font></p>
			</td>
		</tr>
		<tr>
			<td colspan="3">
			<h2>Experimenting using Micro-service to establish your Realtime BigData solution with Storm and Kafka.</h2>
			</td>
		</tr>
		<tr>
			<td><img alt="" src="http://www.tikalk.com/files/yanai.png" style="width: 100px; height: 100px; float: left;" /></td>
			<td colspan="2">
			<p>Kafka is a high-throughput distributed messaging system,<br />
			and Storm is a distributed and&nbsp;fault-tolerant real-time computation.<br />
			Both technologies can be elastically and transparently<br />
			expanded without downtime. This session presents the main concepts of Kafka and Storm ,<br />
			and then we&#39;ll show how a simple stream-processing &quot;micro-service&quot; module is implemented<br />
			and integrated with an existing application using these two technologies.&nbsp;<br />
			60 min&nbsp;By: Yanai Franchi &quot;Tikal&quot;</p>
			</td>
		</tr>
		<tr>
			<td>&nbsp;</td>
			<td><iframe allowfullscreen="" frameborder="0" height="200" marginheight="0" marginwidth="0" scrolling="no" src="http://www.slideshare.net/slideshow/embed_code/32554194" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" width="250"></iframe>&nbsp;<iframe allowfullscreen="" frameborder="0" height="200" scrolling="no" src="//www.youtube.com/embed/2aONGULicSc" width="300"></iframe></td>
		</tr>
		<tr>
			<td colspan="3">
			<h2>Visualizing Data streams using Angular &amp; D3.js&nbsp;</h2>
			</td>
		</tr>
		<tr>
			<td><img alt="" src="http://www.tikalk.com/files/uri.png" style="width: 100px; height: 100px;" /></td>
			<td colspan="2">
			<p>Today&#39;s applications generate huge amount of data. In order to be useful, the data has to be summarized and visualized concisely. In this talk we will learn about D3.js, the web developer Swiss Army Knife for visualizing and working with data. Then we will take it one step further, and integrate our D3-based data visualizations into an Angular.JS application.&nbsp;<br />
			50 min&nbsp;By: Uri Shaked &quot;WatchDox&quot;</p>
			</td>
		</tr>
		<tr>
			<td>&nbsp;</td>
			<td colspan="2"><iframe allowfullscreen="" frameborder="0" height="200" marginheight="0" marginwidth="0" scrolling="no" src="https://docs.google.com/presentation/embed?id=1z4fd8Jo4e001L-DhflqmuzLvePTD0bK1xN25es_5EME&amp;amp;start=false&amp;amp;loop=false&amp;amp;" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" width="250"></iframe>&nbsp;<iframe allowfullscreen="" frameborder="0" height="200" scrolling="no" src="//www.youtube.com/embed/P8d7PYiCK4o" width="300"></iframe></td>
		</tr>
		<tr>
			<td colspan="2" rowspan="1">
			<h2>LivePerson BigData Case Study</h2>
			</td>
		</tr>
		<tr>
			<td><img alt="" src="http://www.tikalk.com/files/ran.png" style="width: 97px; height: 100px;" /></td>
			<td>
			<p>In LivePerson we collect a lot of customer data. The data is stored in Hadoop and can be used for batch processing and querying.&nbsp;Last year, we introduced Kafka and Storm to complete a big data solution for Real-time processing in addition to batch processing.&nbsp;In this&nbsp;lecture&nbsp;we will introduce the integration solution in LivePerson. We will also&nbsp;address some important issues in the&nbsp;solution: 1)&nbsp;High Availability ; 2)&nbsp;Data&nbsp;consistency; 3)&nbsp;Data&nbsp;format&nbsp;and&nbsp;schema enforcement; 4) Auditing data&nbsp;integrity.&nbsp;<br />
			50 min&nbsp;By:Ran Silberman&nbsp;&quot;LivePerson&quot;</p>
			</td>
		</tr>
		<tr>
			<td>&nbsp;</td>
			<td><iframe allowfullscreen="" frameborder="0" height="200" marginheight="0" marginwidth="0" scrolling="no" src="https://docs.google.com/presentation/embed?id=1tezNsfioFh5NglNAJB8Ohc1_PZ1_akY-a8EnKC-Sr-g&amp;amp;start=false&amp;amp;loop=false&amp;amp;" style="border:1px solid #CCC; border-width:1px 1px 0; margin-bottom:5px; max-width: 100%;" width="250"></iframe>â€‹&nbsp;<iframe allowfullscreen="" frameborder="0" height="200" scrolling="no" src="//www.youtube.com/embed/73ohN6K9uh8" width="300"></iframe>;</td>
		</tr>
	</tbody>
</table>
